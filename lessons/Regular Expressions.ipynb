{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular Expressions\n",
    "===================\n",
    "\n",
    "...or, How to find all of what you're looking for.\n",
    "\n",
    "Idea behind REs is to do one search to find, not a word or sequence of words, but a *pattern*. We've all had times when we want to change a word in a document and we have to do several searches, e.g. \"give\", \"gave\", \"given\", before we're sure we have them all. Today we'll learn how to do it more quickly, efficiently, and sometimes correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re   # 're' stands for 'regular expressions'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do is to read in some text to work with. Here is a plain-text file with the contents of _Alice in Wonderland_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fh = open( \"../lessondata/alice.txt\", \"r\" )\n",
    "alicetext = fh.read()\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you get an error when you tried this? You might have to step back and think about about file encodings. Your error might be telling you that the text file is not all in plain old English characters, so you have to know how it was encoded. In this case, the file uses the UTF-8 Unicode encoding.\n",
    "\n",
    "What do you suppose we need to do to fix it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fh = open( \"../lessondata/alice.txt\", \"r\", encoding=\"utf-8\" )\n",
    "alicetext = fh.read()\n",
    "fh.close()\n",
    "print(alicetext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better! Now that we have the text, we can talk about regular expressions. The simplest regular expression is just a word, or a set of words, or a part of a word, that you want to search for. Let's search in the text for the word 'give'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = re.search( \"give\", alicetext )\n",
    "print(result)\n",
    "print(result.start())\n",
    "print(alicetext[result.start():result.end()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.search()` method returns an answer the first time it finds what we're looking for. Here we found a place in the text where the word 'give' occurs, and we printed it out.\n",
    "\n",
    "Regular expressions can get pretty complex! For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "string = \"My email address is tara.andrews@dh.unibe.ch, \" +\\\n",
    "    \"and another email address I have is tla@mit.edu.\"\n",
    "\n",
    "email_re = \"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,4}\"\n",
    "print(re.findall(email_re , string ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is an example of a regular expression to match most valid email addresses. Pretty horrible to look at but gets the job done.\n",
    "\n",
    "You can see in the second example that we usually want all the matches, not just the first one. So we can use `.findall()` instead of `.search()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = re.findall( \"give\", alicetext )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a slightly different function, `.finditer()`, we can go through these results to generate a concordance. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = re.finditer( \"give\", alicetext )\n",
    "for match in result:\n",
    "    begin = match.start() - 30\n",
    "    end = match.end() + 30\n",
    "    print(\"-----\")\n",
    "    print(alicetext[begin:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we remove the line breaks, we'll have written our very own concordance tool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = re.finditer( \"give\", alicetext )\n",
    "for match in result:\n",
    "    begin = match.start() - 30\n",
    "    end = match.end() + 30\n",
    "    context = alicetext[begin:end].replace('\\n', ' ')\n",
    "    print(\"-----\")\n",
    "    print(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of those results has actually returned 'given' rather than 'give'. And what about 'gave'? This is where regular expressions get more interesting.\n",
    "\n",
    "One option is to just list out all the variants you might be looking for, separated by this | character..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall( \"(given|gave|gives|give|giving)\", alicetext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that only got us the lowercase versions, and maybe we want all versions of 'give' no matter the case. That means we have to provide a _flag_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall( \"(given|gave|gives|give)\", alicetext, re.I ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we want to see some of the power of what regular expressions can really do, we can say \"Well all versions if this word start with a 'g' and have a vowel that's either 'i' or 'a', then a 've', and then maybe an 'n' or an 's'. We can write the regular expression to look for a *pattern* like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall( \"(g[ia]v(e[ns]?|ing))\", alicetext, re.I ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what on earth is that? Here is where we talk about flags and metacharacters. In this expression, the flag is `re.I` and the metacharacters were `[]` and `?`.\n",
    "\n",
    "The [] means \"here I expect a single character that might be anything I've listed between the brackets.\"\n",
    "The ? means \"The character I just told you about may or may not be there; match either way.\n",
    "The re.I at the end means \"We don't care whether it's capital or lowercase.\"\n",
    "\n",
    "So we've said we want a 'g', followed by either an 'i' or an 'a', followed by an 've', and possibly (but not necessarily) ending in an 'n' or an 's', and that we don't care what case the word is in.\n",
    "\n",
    "Flags\n",
    "-----\n",
    "Regular expressions usually take some set of *flags* that alter how the expression is treated. The most useful one to know about is the one we used:\n",
    "\n",
    "    re.I   (Case-insensitive: don't pay attention to upper- or lowercase)\n",
    "    \n",
    "\n",
    "Characters, metacharacters, and patterns\n",
    "----------------------------------------\n",
    "\n",
    "A regular expression is a *pattern* specified using *characters* and *metacharacters*. A character is, well, any old thing that can appear in a text file. A metacharacter is a character that doesn't get treated as itself, but rather signals to the regular expression engine that you want to express something more complicated. Typical metacharacters are:\n",
    "\n",
    "    .       (Match any character)\n",
    "    [,+;]   (Match the character if it is any of the things inside the [])\n",
    "    (abc)   (Make abc a group: apply any of the following to the whole thing.)\n",
    "    +       (Match the previous character or group one or more times)\n",
    "    {3}     (Match the previous character or group exactly three times)\n",
    "    {1,4}   (Match the previous character or group between 1 and 4 times)\n",
    "    *       (Match the previous character or group zero or more times)\n",
    "    ?       (If the previous character or group isn't there, treat the pattern as a match anyway)\n",
    "    \\       (The thing that follows is a metacharacter (if normally not) or a character (if normally meta))\n",
    "    \n",
    "So this means that:\n",
    "\n",
    "* `(abc)+` will match `abc` or `abcabc` but not `abac`.\n",
    "* `[abc]+` will match `a` or `b` or `abac` or really any combination of a, b, and c.\n",
    "* If you want to match anything at all, you match `.*`. \n",
    "* If you want to match anything except the empty string, you match `.+`.\n",
    "* If you want to match a period, you match `\\. `; for a plus sign, `\\+ `.\n",
    "\n",
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall( \"[A-Za-z]+!\", alicetext ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have looked for all words that end in an exclamation point...\n",
    "\n",
    "* any character from A-Z, or from a-z ... `[A-Za-z]`\n",
    "* matched multiple times ... `+`\n",
    "* followed by an exclamation point ... `!`\n",
    "\n",
    "There is an easier way to specify this, relying on some more of these metacharacters. The three most important are:\n",
    "\n",
    "    \\w   (match a \"word\" character, which is usually A-Z, a-z, 0-9, and _)\n",
    "    \\d   (match a \"digit\" character, which is generally 0-9)\n",
    "    \\s   (match any sort of \"space\" character, including space, tab, carriage return, etc.)\n",
    "\n",
    "So we can say instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall( \"\\w+!\", alicetext ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see if there are any numbers in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall( \"\\d+\", alicetext ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find things depending on whether they are at the beginning or the end of the line. Here are two more metacharacters:\n",
    "\n",
    "    ^   The beginning\n",
    "    $   The end\n",
    "    \n",
    "So we can make a listing of chapters by searching through the file for where 'chapter' appears at the beginning of the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for heading in re.finditer( \"^CHAPTER .*$\", alicetext):\n",
    "    print(heading.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmmm, that didn't work. Why not? Well, what word(s) does Python think is at the beginning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(re.findall(\"^\\w+\", alicetext))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aha. That's the single word (well, part of a word) that is at the beginning of the whole \"alicetext\" string! But we really want `^` and `$` to match the beginning and end of every line. So we need another flag:\n",
    "\n",
    "    re.M   Multi-line mode: ^ and $ apply to every line, not just the string itself.\n",
    "    \n",
    "When we use this flag, we change what `^` and `$` mean, and get what we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for heading in re.finditer( \"^CHAPTER .*$\", alicetext, re.M):\n",
    "    print(heading.group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this 'group' thing? It's another feature of regular expressions: every time you put something in parentheses in a regular expression, you can get at it separately from the rest of the thing you matched. The 0th group is always the whole match, and then the groups are numbered in the order that their parentheses start.\n",
    "\n",
    "This is very useful if, for instance, you want to print out the chapter numbers and titles by themselves. We just put the part we want to keep in parentheses, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chapterlist = {}\n",
    "\n",
    "for heading in re.finditer( \"^CHAPTER ([IVX]+)\\.\\s+(.*)$\", alicetext, re.M):\n",
    "    chapterlist[heading.group(1)] = heading.group(2)\n",
    "    \n",
    "for k in sorted(chapterlist):\n",
    "    print(\"%-4s : %s\" % (k, chapterlist[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expressions module also has another very useful feature, which is that you can not only find things, you can replace them. This is the `sub` function, meaning \"substitute\".\n",
    "\n",
    "Let's say that Alice has reached her teenage years and is exploring her identity, and wants to be known for a while by her middle name, Pleasance. We can fix the text by substituting the new name for the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ptext = re.sub( \"Alice\", \"Pleasance\", alicetext, flags=re.I)\n",
    "print(ptext[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third useful thing you can do with regular expressions, that will be important for the homework, is to use a pattern to split up some text. Let's say that you have a shopping list that looks like this:\n",
    "\n",
    "3 bananas, 3 apples, 500g steak, 1 bottle of beer\n",
    "\n",
    "and you want to make a proper list out of it. You'll need to do some matching and some splitting up!\n",
    "\n",
    "First we can see that the list is separated by commas. We can split it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shopping_list = \"3 bananas, 3 apples, 500g steak,  6 bottles of beer\"\n",
    "things = re.split(',\\s+', shopping_list)\n",
    "for item in things:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks an awful lot like the string splitting function that we already knew about. But what if we got this list from OCR, and it looks rather more untidy? Here is where regular expressions help a lot more.\n",
    "\n",
    "In this case we want to split up the list, but in doing that we want to throw away any commas or periods, as well as empty space before and after them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shopping_list = \"3 bananas. 3 apples ... 500g steak,6 bottles of beer  \"\n",
    "things = re.split('\\s*[.,]+\\s*', shopping_list)\n",
    "for item in things:\n",
    "    print(item + '!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have the problem of that empty space after the beer. So when we are cleaning up text, the first thing we almost always do is to get rid of any space at the beginning and at the end. This is something you will see (and do) a lot when using regular expressions on real text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shopping_list = \"3 bananas. 3 apples ,, 500g steak, 6 bottles of beer  \"\n",
    "## These lines, or lines like them, are used a lot!! \n",
    "## Don't forget the re.M flag if you want to do this for all the lines in a file.\n",
    "shopping_list = re.sub(\"^\\s+\", '', shopping_list)\n",
    "shopping_list = re.sub(\"\\s+$\", '', shopping_list)\n",
    "## Now we can get on with the rest of the program.\n",
    "things = re.split('\\s*[.,]+\\s*', shopping_list)\n",
    "print(things)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we have our list, but we should be able to split it up into \"quantity\" and \"item\". We can observe a few rules:\n",
    "\n",
    "- Quantities are usually numbers, but might be amounts like '500g' or '6 bottles'.\n",
    "- If the quantity is more than one word, there will generally be an 'of' in there somewhere.\n",
    "- If we can't split on the 'of', then we just split the words.\n",
    "\n",
    "Let's do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shopping = {}\n",
    "\n",
    "for thing in things:\n",
    "    if re.search('of', thing):\n",
    "        parsed = re.split('\\s+of\\s+', thing)\n",
    "    else:\n",
    "        parsed = thing.split()\n",
    "    shopping[parsed[1]] = parsed[0]\n",
    "    \n",
    "print(shopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(url=\"http://imgs.xkcd.com/comics/regular_expressions.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
